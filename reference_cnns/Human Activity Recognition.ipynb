{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Activity Recognition Using Accelerometer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Link: http://www.cis.fordham.edu/wisdm/dataset.php\n",
    "\n",
    "The WISDM dataset contains six different labels (Downstairs, Jogging, Sitting, Standing, Upstairs, Walking). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_activities = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "train_path = 'C:/Users/uwu/Documents/CMU/2022 Spring/18743/18-743_Project/data'\n",
    "source_files = glob.glob(train_path + '/*.csv')\n",
    "\n",
    "dataframes = []\n",
    "num = 1\n",
    "for file in source_files:\n",
    "    df = pd.read_csv(file) # additional arguments up to your needs\n",
    "    df['user'] = num\n",
    "    df['time'] = range(0, len(df))\n",
    "    df = df.rename(columns={'label': 'activity'})\n",
    "    num = num + 1\n",
    "    df = df[df.activity != 0]\n",
    "    dataframes.append(df)\n",
    "\n",
    "df_all = pd.concat(dataframes, axis=0)\n",
    "df_all = df_all[['user', 'activity', 'time', 'x', 'y', 'z']]\n",
    "data = df_all\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_path = 'C:/Users/uwu/Documents/CMU/2022 Spring/18743/18-743_Project/03_a.csv'\n",
    "predict_path = 'C:/Users/uwu/Documents/CMU/2022 Spring/18743/18-743_Project/data/15.csv'\n",
    "\n",
    "df_predict = pd.read_csv(predict_path) # additional arguments up to your needs\n",
    "df_predict['user'] = 16\n",
    "df_predict['time'] = range(0, len(df_predict))\n",
    "df_predict = df_predict.rename(columns={'label': 'activity'})\n",
    "df_predict = df_predict[df_predict.activity != 0]\n",
    "df_predict = df_predict[['user', 'activity', 'time', 'x', 'y', 'z']]\n",
    "df_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['user', 'activity', 'time', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance this data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['x'] = data['x'].astype('float')\n",
    "data['y'] = data['y'].astype('float')\n",
    "data['z'] = data['z'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict['x'] = df_predict['x'].astype('float')\n",
    "df_predict['y'] = df_predict['y'].astype('float')\n",
    "df_predict['z'] = df_predict['z'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = data['activity'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_activity(activity, data):\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, figsize=(15, 7), sharex=True)\n",
    "    plot_axis(ax0, data['time'], data['x'], 'X-Axis')\n",
    "    plot_axis(ax1, data['time'], data['y'], 'Y-Axis')\n",
    "    plot_axis(ax2, data['time'], data['z'], 'Z-Axis')\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    fig.suptitle(activity)\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    plt.show()\n",
    "\n",
    "def plot_axis(ax, x, y, title):\n",
    "    ax.plot(x, y, 'g')\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\n",
    "    ax.set_xlim([min(x), max(x)])\n",
    "    ax.grid(True)\n",
    "\n",
    "for activity in activities:\n",
    "    data_for_plot = data[(data['activity'] == activity)][:Fs*10]\n",
    "    plot_activity(activity, data_for_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(['user', 'time'], axis = 1).copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = df_predict.drop(['user', 'time'], axis = 1).copy()\n",
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data = pd.DataFrame()\n",
    "\n",
    "for i in range(1, num_activities+1):\n",
    "    balanced_data = pd.concat([balanced_data, df[df['activity']==i].head(df['activity'].value_counts().min()).copy()])\n",
    "\n",
    "print(balanced_data.shape)\n",
    "print(balanced_data['activity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "balanced_data['label'] = label.fit_transform(balanced_data['activity'])\n",
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre['label'] = label.fit_transform(df_pre['activity'])\n",
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = balanced_data[['x', 'y', 'z']]\n",
    "y = balanced_data['label']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = df_pre[['x', 'y', 'z']]\n",
    "y_pred = df_pre['label']\n",
    "X_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "scaled_X = pd.DataFrame(data = X, columns = ['x', 'y', 'z'])\n",
    "scaled_X['label'] = y.values\n",
    "\n",
    "scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_pred = scaler.fit_transform(X_pred)\n",
    "\n",
    "scaled_X_pred = pd.DataFrame(data = X_pred, columns = ['x', 'y', 'z'])\n",
    "scaled_X_pred['label'] = y_pred.values\n",
    "\n",
    "scaled_X_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 20\n",
    "frame_size = Fs*4 # 80\n",
    "hop_size = Fs*2 # 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(df, frame_size, hop_size):\n",
    "\n",
    "    N_FEATURES = 3\n",
    "\n",
    "    frames = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - frame_size, hop_size):\n",
    "        x = df['x'].values[i: i + frame_size]\n",
    "        y = df['y'].values[i: i + frame_size]\n",
    "        z = df['z'].values[i: i + frame_size]\n",
    "        \n",
    "        # Retrieve the most often used label in this segment\n",
    "        label = stats.mode(df['label'][i: i + frame_size])[0][0]\n",
    "        frames.append([x, y, z])\n",
    "        labels.append(label)\n",
    "\n",
    "    # Bring the segments into a better shape\n",
    "    frames = np.asarray(frames).reshape(-1, frame_size, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return frames, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_frames(scaled_X, frame_size, hop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred, y_pred = get_frames(scaled_X_pred, frame_size, hop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape, X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(6686, 80, 3, 1)\n",
    "X_test = X_test.reshape(1672, 80, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape, X_test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (2, 2), activation = 'relu', input_shape = X_train[0].shape))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate = 0.001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 10, validation_data= (X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learningCurve(history, epochs):\n",
    "  # Plot training & validation accuracy values\n",
    "  epoch_range = range(1, epochs+1)\n",
    "  plt.plot(epoch_range, history.history['accuracy'])\n",
    "  plt.plot(epoch_range, history.history['val_accuracy'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(epoch_range, history.history['loss'])\n",
    "  plt.plot(epoch_range, history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learningCurve(history, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = model.predict(X_test)\n",
    "y_classes = y_p.argmax(axis=-1)\n",
    "y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_1 = model.predict(X_pred)\n",
    "y_predict_classes  = y_predict_1.argmax(axis=-1)\n",
    "y_predict_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Generate the confusion matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_classes)\n",
    "\n",
    "num1 = 0\n",
    "\n",
    "for i in range(len(y_classes)):\n",
    "    if (y_classes[i] != y_test[i]):\n",
    "        num1 = num1 + 1\n",
    "print(1-num1/len(y_classes))\n",
    "\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_pred, y_predict_classes)\n",
    "\n",
    "num1 = 0\n",
    "\n",
    "for i in range(len(y_predict_classes)):\n",
    "    if (y_pred[i] != y_predict_classes[i]):\n",
    "        num1 = num1 + 1\n",
    "print(1-num1/len(y_predict_classes))\n",
    "\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
